Perfecto — buen apuntado. Con lo que comentas hay dos ejes a resolver:

1. Los pods necesitan salida a Internet (no sólo DNS) y quieres que todo salga por tu proxy/egress IP.


2. Necesitas también el DNS interno de OpenShift (CoreDNS) para resolver *.svc.cluster.local y nombres internos, pero no quieres que ese DNS haga resoluciones externas directo a Internet (porque eso esquivaría tu proxy).



Te explico las opciones prácticas, sus límites y la(s) configuración(es) que puedes aplicar ahora mismo.


---

Idea central (resumen)

La opción más robusta es combinar control de la ruta del DNS + control del comportamiento del Pod con dnsPolicy/dnsConfig.

Dos enfoques válidos (combinables):

1. Forzar que los pods usen un DNS local (tu proxy DNS) con dnsPolicy: None y dnsConfig — pones la IP(s) del proxy como nameservers y las IP(s) del DNS de cluster como fallback. Esto hace que los pods consulten primero al proxy. (Kubernetes permite dnsPolicy: None y usar dnsConfig para controlar /etc/resolv.conf del pod). 


2. Hacer que el DNS del clúster (CoreDNS) haga sus resoluciones ascendentes a través del proxy/egress — así, incluso si los pods usan el DNS del clúster (modo ClusterFirst), el DNS del clúster no podrá resolver directo a Internet sino que pasará por tu proxy/egress. Esto se consigue a nivel de CoreDNS (forwarders) o a nivel de red (EgressFirewall / EgressNetworkPolicy que obligue al CoreDNS a usar la egress IP). 




Ambas estrategias pueden combinarse para cubrir todos los casos (pods controlados + asegurarte que el DNS-clúster no fuga).


---

1) Usar dnsPolicy: None + dnsConfig en los pods (control fino del /etc/resolv.conf)

Ventaja: controlas exactamente qué servidores DNS ve el pod y el orden de consulta (nameservers, search, options).
Limitaciones importantes: nameservers deben ser IP (no puedes poner un service name), máximo 3 nameservers, y dnsPolicy: None te obliga a rellenar dnsConfig con cuidado (puede romper resoluciones si te olvidas de poner el DNS-cluster para nombres internos). 

Ejemplo de Pod/Deployment (pon esto en los pods del namespace que quieres forzar):

apiVersion: v1
kind: Pod
metadata:
  name: ejemplo-dns
spec:
  dnsPolicy: None
  dnsConfig:
    nameservers:
      - 192.0.2.5    # <- IP del proxy DNS / egress-router (PRIMARIO para resoluciones externas)
      - 10.96.0.10   # <- IP del Service Cluster DNS (CoreDNS) para resoluciones internas
    searches:
      - myns.svc.cluster.local
      - svc.cluster.local
      - cluster.local
    options:
      - name: ndots
        value: "2"
  containers:
  - name: app
    image: busybox
    command: ["sleep","3600"]

Cómo funciona en la práctica:

El pod consultará primero 192.0.2.5. Si ese resolver no conoce nombres internos *.svc.cluster.local, fallará y el sistema probará el siguiente nameserver (10.96.0.10).

El orden y comportamiento dependen del resolver y del ndots — por eso conviene ajustar search y ndots para que las búsquedas de nombres cortos consulten al DNS-cluster primero si quieres. 


Cuando usar esto: si tu proxy DNS sabe resolver todo lo externo pero no sabe/puede resolver nombres cluster.local, pon también el cluster DNS como fallback. Si tu proxy sí puede resolver internos (ej. le haces forwarding a CoreDNS) entonces pon sólo el proxy como nameserver.


---

2) Hacer que CoreDNS (DNS del cluster) solo suba via proxy (recomendado si no quieres tocar todos los pods)

Si dejas dnsPolicy: ClusterFirst (por defecto), los pods usan CoreDNS. Entonces debes evitar que CoreDNS haga upstream directo a Internet. Dos formas:

A) Configurar CoreDNS para que su forward o proxy use como upstream la IP del proxy/egress (o un servidor interno que reenvíe al proxy). Esto se hace ajustando el ConfigMap de CoreDNS (DNS operator en OpenShift) para que use tus forwarders. Requiere privilegios de admin y recargar CoreDNS. 

B) Forzar por red (OpenShift): usa EgressFirewall / EgressNetworkPolicy para que el Pod/Service de CoreDNS solo pueda salir a Internet por la IP del proxy/egress o directamente bloquear toda egress excepto hacia el proxy. Así, aunque CoreDNS intente resolver a servidores upstream públicos, la red obligará a que el tráfico salga por tu egress (o lo bloquee). Esto es útil si no quieres tocar la configuración interna de CoreDNS. 

Consejo práctico: combina A + B (configurar CoreDNS y bloquear egress no deseado). Así cubres tanto la configuración como la política de red.


---

3) Qué elegir según tu situación (quick decision)

Si puedes cambiar CoreDNS (eres admin): configura CoreDNS para que haga forward a tu proxy/egress y, además, crea una regla de egress para que CoreDNS solo pueda salir por la IP del proxy. Resultado: los pods con ClusterFirst usarán CoreDNS y no se saltará el proxy. 

Si no puedes tocar CoreDNS y no quieres cambiar todos los pods: usa dnsPolicy: None + dnsConfig en los pods críticos y pon el proxy como primer nameserver y el cluster DNS como fallback. Ojo con el límite de 3 nameservers y con pods que usan hostNetwork. 



---

4) Riesgos / límites prácticos (tener en cuenta)

dnsConfig.nameservers requiere IPs, no nombres de servicio. Si tu resolver es un Pod cuyo IP cambia, necesitas referenciar su Service ClusterIP (que es fija) — pero recuerda que dnsConfig sólo admite IPs, no Service names; por tanto usa la ClusterIP del Service si procede. 

Máximo 3 nameservers en dnsConfig.

hostNetwork: true o pods privilegiados pueden esquivar controles.

dnsPolicy: None hace que el pod no tenga la configuración automática de Kubernetes — cuidado con buscar SRV, cluster.local, etc. Ajusta search y ndots. 



---

5) Pasos prácticos recomendados (ordenados, aplicables ya)

1. (Alta prioridad / admin): modifica CoreDNS para que sus upstreams sean tu proxy (edita ConfigMap de CoreDNS / DNS Operator) — así no hace resoluciones ascendentes directas. Ver doc de Customizing DNS Service / DNS operator. 


2. (Red): crea EgressFirewall / EgressNetworkPolicy para que el Pod/Service del CoreDNS solo pueda acceder al proxy/egress IP (y denegar el resto). Con OVN/OpenShift esto se puede por namespace/objeto. 


3. (Por pod si no puedes tocar CoreDNS): usa dnsPolicy: None + dnsConfig en los pods del namespace problemático, con nameservers apuntando primero a la IP de tu proxy y luego a la IP del cluster DNS (si necesitas internal fallback). Usa search y ndots para optimizar. (Ejemplo YAML arriba). 


4. Pruebas:

Desde un pod con dnsPolicy: None, dig @<IP_PROXY> google.com y dig @<CLUSTER_DNS> mysvc.myns.svc.cluster.local.

Ver tráfico saliente del CoreDNS pod/service y confirmar que sale por la egress IP.

Ver logs de CoreDNS si hay fallos de reenvío. 





---

6) Si quieres, te doy ya YAMLs listos

Puedo darte:

el Pod/Deployment de ejemplo (con dnsPolicy: None) listo para aplicar en tu namespace, y

un ejemplo de ConfigMap (fragmento) para CoreDNS (forward plugin) que haga upstream al proxy, y

un EgressFirewall/EgressNetworkPolicy de ejemplo para que CoreDNS solo pueda salir por la IP del proxy.


Dime (no necesito que repitas mucho):

IP del proxy DNS / egress (por ejemplo 192.0.2.5),

IP del Service Cluster DNS (si la sabes, ej. 10.96.0.10),

si tu CNI es OVN o OpenShift SDN (para dar el CR correcto),


y te los genero en YAML listos para aplicar. Si prefieres que te muestre primero el fragmento de CoreDNS para confirmar la sintaxis, lo pongo ya.

# change_passwords.ps1
param(
    [string]$CsvPath = ".\users.csv",   # ruta al CSV
    [string]$PscpExe = "pscp.exe",     # pscp (PuTTY) - en PATH o ruta completa
    [string]$PlinkExe = "plink.exe"    # plink (PuTTY) - en PATH o ruta completa
)

if (-not (Test-Path $CsvPath)) {
    Write-Error "No existe el CSV en '$CsvPath'."
    exit 1
}

# Contenido del script expect (tal cual lo diste)
$expectContent = @'
#!/usr/bin/expect -f
set user [lindex $argv 0]
set old  [lindex $argv 1]
set new  [lindex $argv 2]

spawn passwd $user
expect "Current password:"
send "$old\r"
expect "New password:"
send "$new\r"
expect "Retype new password:"
send "$new\r"
expect eof
'@

# Archivo temporal local para el expect
$tempExpectLocal = [System.IO.Path]::GetTempFileName()
# reemplazamos la extensión para que sea .expect (opcional)
$tempExpectLocal = [System.IO.Path]::ChangeExtension($tempExpectLocal, ".expect")
Set-Content -Path $tempExpectLocal -Value $expectContent -Encoding ASCII

# Función para hacer quoting seguro de argumentos para shell remota (envolvemos en comillas simples)
function QuoteForRemote($s) {
    if ($null -eq $s) { return "''" }
    # reemplaza cada ' por '"'"'  (convención para pasar comillas simples dentro de comillas simples en sh)
    $escaped = $s -replace "'", "'\"'\"'"
    return "'$escaped'"
}

$rows = Import-Csv -Path $CsvPath

foreach ($row in $rows) {
    $host = $row.Host.Trim()
    $user = $row.User.Trim()
    $old = $row.OldPassword
    $new = $row.NewPassword

    if (-not $host -or -not $user) {
        Write-Warning "Registro con Host o User vacío, omitiendo..."
        continue
    }

    Write-Host "Procesando $user@$host ..."

    # Ruta remota temporal
    $remotePath = "/tmp/change_pass.expect"

    # 1) Subir el script expect vía pscp (autenticación con -pw $old)
    $pscpArgs = @("-pw", $old, $tempExpectLocal, "$user@$host:$remotePath")
    Write-Host "  Subiendo expect a $host:$remotePath ..."
    $pscpResult = & $PscpExe @pscpArgs
    $pscpExit = $LASTEXITCODE
    if ($pscpExit -ne 0) {
        Write-Error "  Falló pscp (exit $pscpExit). Salida: $pscpResult"
        continue
    }

    # 2) Dar permisos y ejecutar el script expect remotamente con plink
    # Construimos el comando remoto: chmod +x /tmp/change_pass.expect && expect /tmp/change_pass.expect 'user' 'old' 'new'
    $qUser = QuoteForRemote $user
    $qOld  = QuoteForRemote $old
    $qNew  = QuoteForRemote $new

    $remoteCmd = "chmod +x $remotePath && /usr/bin/expect $remotePath $qUser $qOld $qNew"

    Write-Host "  Ejecutando cambio de password en $host ..."
    $plinkArgs = @("-pw", $old, "$user@$host", $remoteCmd)
    $plinkResult = & $PlinkExe @plinkArgs
    $plinkExit = $LASTEXITCODE

    if ($plinkExit -ne 0) {
        Write-Error "  Falló plink (exit $plinkExit). Salida: $plinkResult"
        continue
    }

    Write-Host "  Operación terminada para $user@$host."
}

# limpiar archivo temporal local
Remove-Item -Path $tempExpectLocal -ErrorAction SilentlyContinue
Write-Host "Hecho."

Host,User,OldPassword,NewPassword
linux01.example.com,juan,oldPass123,newPass456

.\change_passwords.ps1 -CsvPath ".\users.csv"
